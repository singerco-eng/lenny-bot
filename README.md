# ğŸ¤– Lenny Bot

An intelligent Q&A agent for AccuLynx that understands the entire platform and can answer questions about any aspect of the software.

---

### ğŸ¤– AI Agents: Start Here

**If you're an AI agent (Claude, GPT, etc.), read `docs/AI_AGENT_QUICKSTART.md` first.**

Key rules:
- Use `scripts/crawler_utils.py` for ALL database operations
- Never write inline Python for saves/inserts
- Run `python scripts/crawler_utils.py unexplored` to see work queue
- Check `.cursorrules` for project conventions

---

## ğŸ¯ Project Goals

1. **Q&A Agent**: Answer questions like "How do I create a job?" or "What reports are available?"
2. **KB-Guided Crawling**: Use KB knowledge to intelligently crawl the web app
3. **AI-Powered Understanding**: GPT-4o generates descriptions with KB context
4. **RAG Search**: Vector embeddings enable semantic search across all content

### Future: Action Agent (Optional)

The architecture preserves the ability to add Action Agent features later:
- Element-level labeling for GUI automation
- Form filling and submission
- Network monitoring for data modification tracking

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LENNY BOT                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Data Collection          Agent (RunPod)      Admin (Vercel)â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  â€¢ KB Scraper âœ“           â€¢ Self-hosted LLM   â€¢ Next.js UI  â”‚
â”‚  â€¢ Video Processor âœ“      â€¢ RAG Pipeline âœ“    â€¢ Data Mgmt   â”‚
â”‚  â€¢ KB-Guided Crawler      â€¢ Guardrails        â€¢ Chat Test   â”‚
â”‚  â€¢ AI Descriptions        â€¢ Embeddings âœ“      â€¢ Sitemap Viewâ”‚
â”‚                                                              â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                    â”‚    Supabase     â”‚                      â”‚
â”‚                    â”‚  â€¢ PostgreSQL   â”‚                      â”‚
â”‚                    â”‚  â€¢ pgvector     â”‚                      â”‚
â”‚                    â”‚  â€¢ Storage      â”‚                      â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Current Progress

### âœ… Phase 1: Knowledge Base (COMPLETE)
- [x] KB scraper (297 articles discovered)
- [x] Video discovery (115 videos found)
- [x] Video processing pipeline (transcription + frame analysis)
- [x] 6,322 video steps extracted

### âœ… Phase 2: RAG Pipeline (COMPLETE)
- [x] pgvector extension and embedding schema
- [x] Embedding generator (content, video steps, summaries)
- [x] Semantic search with similarity scoring
- [x] Q&A chain with LLM integration
- [x] Swappable LLM provider (OpenAI, Claude, Ollama)
- [x] Interactive chat CLI (ask_lenny.py)

### ğŸ§¹ Phase 3: Fresh Start Cleanup (COMPLETE - Dec 22, 2024)
- [x] Archived old app crawl data (156 pages â†’ `_archived_app_pages`)
- [x] Archived navigation data (236 items â†’ `_archived_global_nav_items`)
- [x] Archived 102 old files to `_archived/`
- [x] Deleted regenerating directories (chrome_profile, browser-data)
- [x] Created fresh schema for KB-guided crawling

### âœ… Phase 4: KB Analysis (COMPLETE - Dec 22, 2024)
> See: `docs/EPIC_KB_GUIDED_CRAWLING.md` for full epic documentation

Analyzed KB embeddings to understand AccuLynx:
- [x] Extracted 21 product areas from KB articles
- [x] Identified 20 key features with product area mappings
- [x] Calendar deep dive for first product area
- [x] Saved analysis to `docs/kb_analysis_*.md`

### â³ Phase 5: KB-Guided App Crawling (IN PROGRESS)
> Epic documentation: `docs/EPIC_KB_GUIDED_CRAWLING.md`
> Crawler approach: `docs/AI_CRAWLER_APPROACH.md`

Feature-centric crawl of app with KB context:
- [x] Create global context document (`docs/GLOBAL_CONTEXT.md`)
- [x] Build feature-centric database schema (13 product areas seeded)
- [x] **Claude-as-Crawler approach** - using Claude in Cursor as intelligent agent
- [ ] Crawl Job Overview + tabs (starting point)
- [ ] Flag unknown items for human review
- [ ] Generate feature â†’ location mappings

**Crawler Approach**: Instead of Python code, we use Claude in Cursor with MCP browser tools. This eliminates code maintenance while providing intelligent, context-aware crawling. See `docs/AI_CRAWLER_APPROACH.md`.

### âœ… Phase 6: Admin Review UI (SETUP COMPLETE)

React app styled like AccuLynx for reviewing crawl results:
- [x] Set up React + Vite + TypeScript project (`/admin`)
- [x] AccuLynx design system extraction + showcase page
- [ ] Page browser with screenshots (after first crawl)
- [ ] Actions inventory per page
- [ ] **Product areas & features viewer**
- [ ] Unknown items review queue
- [ ] Gap report (KB vs app)

### â³ Phase 7: Agent Development (FUTURE)
- [ ] RunPod infrastructure setup
- [ ] Self-hosted LLM deployment
- [ ] RAG integration
- [ ] Guardrails configuration

---

## ğŸ“Š Database Status

### Active Tables (Ready for Use)

| Table | Rows | Description |
|-------|------|-------------|
| `source_urls` | 297 | KB article URLs |
| `content_chunks` | 150 | KB content with embeddings |
| `kb_videos` | 115 | Video metadata |
| `video_steps` | 6,322 | Transcribed steps with embeddings |
| `app_pages` | 0 | **Fresh** - ready for KB-guided crawl |
| `page_containers` | 0 | **Fresh** - modals, drawers, dropdowns |
| `global_navigation` | 0 | **Fresh** - nav structure |
| `nav_items` | 0 | **Fresh** - nav links |

### Archived Tables (Preserved Data)

| Table | Rows | Description |
|-------|------|-------------|
| `_archived_app_pages` | 156 | Old app pages (before KB-guided) |
| `_archived_page_elements` | 1,205 | Old element data |
| `_archived_global_nav_items` | 236 | Old navigation items |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+ 
- Chrome browser (for authenticated scraping)
- Supabase account (configured)
- OpenAI API key (for embeddings and descriptions)

### Installation

```bash
cd C:\Users\singe\lenny-bot

# Create virtual environment
python -m venv venv
venv\Scripts\activate

# Install dependencies
python -m pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium

# Configure environment
# Copy env.example.txt to .env and fill in your credentials
```

### Using Lenny Bot (Q&A)

The RAG pipeline is ready! Ask Lenny questions about AccuLynx:

```bash
# Interactive chat mode (recommended)
bat\rag\ASK_LENNY.bat

# Or use Python directly:
python scripts/ask_lenny.py "How do I create a new job?"
python scripts/ask_lenny.py --search "reports"  # Search only, no LLM
```

### Running the Claude-as-Crawler

We use Claude in Cursor as an intelligent crawler (no Python code needed):

```bash
# Step 1: Start Chrome with debug port
chrome.exe --remote-debugging-port=9222 --user-data-dir="C:\temp\chrome-debug"

# Step 2: In Chrome, navigate to AccuLynx and log in

# Step 3: In Cursor, tell Claude:
"The browser is ready on Job Overview. Let's start crawling."
```

Claude will:
- Take browser snapshots to discover elements
- Intelligently classify what to explore vs document
- Click through tabs and actions
- Save findings to the database
- Ask for guidance when uncertain

See `docs/AI_CRAWLER_APPROACH.md` for full details.

### Database Management

```bash
# Run migrations
bat\database\RUN_MIGRATIONS.bat

# Generate embeddings for new content
bat\rag\GENERATE_EMBEDDINGS.bat
```

### Processing KB Videos

KB articles often contain training videos. Extract their content for RAG:

```bash
# Prerequisites: Install yt-dlp and ffmpeg
pip install yt-dlp
# Download ffmpeg from https://ffmpeg.org/download.html

# Discover videos in KB articles (re-scrape KB)
bat\scrapers\RUN_KB_SCRAPER.bat

# Process discovered videos (transcribe + analyze)
bat\scrapers\PROCESS_KB_VIDEOS.bat
```

---

## ğŸ“ Project Structure

```
lenny-bot/
â”œâ”€â”€ _archived/                    # Old files (preserved for reference)
â”‚   â”œâ”€â”€ crawl_data/              # Old JSONs, logs, sitemaps
â”‚   â”œâ”€â”€ screenshots/             # Old screenshot directories
â”‚   â”œâ”€â”€ scripts/                 # Old test/debug scripts
â”‚   â””â”€â”€ scrapers/                # Deprecated scrapers (action_explorer, etc.)
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py              # Environment configuration
â”‚   â”œâ”€â”€ product_areas.py         # AccuLynx product taxonomy
â”‚   â”œâ”€â”€ noise_patterns.py        # Content filtering rules
â”‚   â”œâ”€â”€ page_templates.py        # UI template patterns
â”‚   â””â”€â”€ navigation_structure.py  # Header navigation config
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ supabase_client.py       # Supabase connection
â”‚   â”œâ”€â”€ models.py                # Pydantic data models (KB)
â”‚   â”œâ”€â”€ app_models.py            # Pydantic data models (App)
â”‚   â””â”€â”€ migrations/              # SQL schema files (001-019)
â”‚
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ kb_scraper.py            # Knowledge Base scraper âœ“
â”‚   â”œâ”€â”€ kb_guided_crawler/       # Utilities for Claude-as-Crawler
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Module exports
â”‚   â”‚   â”œâ”€â”€ url_normalizer.py    # URL â†’ pattern conversion
â”‚   â”‚   â”œâ”€â”€ kb_context.py        # KB semantic search context
â”‚   â”‚   â”œâ”€â”€ page_describer.py    # GPT-4o descriptions (when needed)
â”‚   â”‚   â””â”€â”€ screenshot_manager.py # Local screenshot storage
â”‚   â”œâ”€â”€ _archive_python_crawler/ # Archived Python crawler code
â”‚   â”œâ”€â”€ browser_auth.py          # Multi-strategy browser auth
â”‚   â””â”€â”€ base_scraper.py          # Abstract scraper base class
â”‚
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ video_processor.py       # Video transcription & analysis âœ“
â”‚   â”œâ”€â”€ content_classifier.py    # GPT-4o-mini classification
â”‚   â”œâ”€â”€ embedder.py              # OpenAI embeddings
â”‚   â””â”€â”€ chunker.py               # Intelligent content chunking
â”‚
â”œâ”€â”€ rag/                          # RAG Pipeline âœ“
â”‚   â”œâ”€â”€ llm_provider.py          # Swappable LLM backends
â”‚   â”œâ”€â”€ embeddings.py            # Generate vector embeddings
â”‚   â”œâ”€â”€ search.py                # Semantic similarity search
â”‚   â””â”€â”€ qa_chain.py              # Q&A chain (search â†’ LLM â†’ answer)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ask_lenny.py             # Interactive Q&A CLI âœ“
â”‚   â”œâ”€â”€ generate_embeddings.py   # Generate embeddings âœ“
â”‚   â”œâ”€â”€ scrape_kb.py             # Run KB scraper
â”‚   â”œâ”€â”€ process_kb_videos.py     # Process videos
â”‚   â”œâ”€â”€ cleanup_project.py       # Project cleanup utility
â”‚   â””â”€â”€ run_migrations.py        # Run database migrations
â”‚
â”œâ”€â”€ bat/                         # Batch scripts
â”‚   â”œâ”€â”€ rag/                     # RAG commands
â”‚   â”œâ”€â”€ scrapers/                # Scraper commands
â”‚   â””â”€â”€ database/                # DB commands
â”‚
â”œâ”€â”€ admin/                       # Admin UI (React + Vite)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/DesignSystem.tsx  # Design system showcase
â”‚   â”‚   â””â”€â”€ index.css               # AccuLynx styles
â”‚   â”œâ”€â”€ tailwind.config.js          # AccuLynx theme
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ AI_CRAWLER_APPROACH.md  # Claude-as-Crawler methodology
â”‚   â”œâ”€â”€ GLOBAL_CONTEXT.md           # AccuLynx product context
â”‚   â””â”€â”€ EPIC_KB_GUIDED_CRAWLING.md  # Epic documentation
â”‚
â”œâ”€â”€ video_processing/            # Video output (audio, frames)
â”œâ”€â”€ venv/                        # Python virtual environment
â”‚
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ REFACTORING_PLAN.md          # Migration plan with phases
â”œâ”€â”€ DEPRECATED.md                # Deprecated components reference
â””â”€â”€ PROGRESS.md                  # Development history
```

---

## ğŸ§  Data Collection Philosophy

### Q&A Agent Approach (Current)

The Q&A agent needs to understand AccuLynx well enough to answer questions. This requires:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Q&A AGENT DATA MODEL                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. KB ARTICLES + VIDEOS (COMPLETE âœ“)                        â”‚
â”‚     "How do you perform each task?"                          â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚     â€¢ 297 help articles with embeddings                      â”‚
â”‚     â€¢ 115 training videos transcribed                        â”‚
â”‚     â€¢ 6,322 step-by-step instructions                        â”‚
â”‚                                                              â”‚
â”‚  2. PAGE SCREENSHOTS + DESCRIPTIONS (NEXT)                   â”‚
â”‚     "What does each screen look like?"                       â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚     â€¢ Screenshot of every page                               â”‚
â”‚     â€¢ AI description WITH KB context                         â”‚
â”‚     â€¢ Page type (dashboard, list, form, settings)            â”‚
â”‚                                                              â”‚
â”‚  3. CONTAINER SCREENSHOTS + DESCRIPTIONS                     â”‚
â”‚     "What do modals and drawers contain?"                    â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚     â€¢ Screenshot of every modal, drawer, dropdown            â”‚
â”‚     â€¢ AI description WITH KB context                         â”‚
â”‚     â€¢ What button/link opens each container                  â”‚
â”‚                                                              â”‚
â”‚  4. NAVIGATION STRUCTURE                                     â”‚
â”‚     "How do you get to each page?"                           â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚     â€¢ Complete menu structure                                â”‚
â”‚     â€¢ Links between pages                                    â”‚
â”‚     â€¢ Menu screenshots                                       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Configuration

### Environment Variables (.env)

| Variable | Description |
|----------|-------------|
| `SUPABASE_URL` | Your Supabase project URL |
| `SUPABASE_SERVICE_ROLE_KEY` | Service role key for full access |
| `DATABASE_URL` | PostgreSQL connection string (pooler) |
| `OPENAI_API_KEY` | For GPT-4o + text-embedding-3-large |
| `CHROME_DEBUG_PORT` | Port for browser connection (default: 9222) |

### Key URLs

- **AccuLynx KB**: https://support.acculynx.com/hc/en-us
- **AccuLynx App (Staging)**: https://stage-my.acculynx.com/dashboard

---

## ğŸ“ˆ Metrics

### KB Coverage

| Metric | Count |
|--------|-------|
| **KB Articles** | 297 |
| **KB Videos** | 115 |
| **Video Steps** | 6,322 |
| **Content Chunks** | 150 |

### Cost Estimates

| Component | Monthly Cost |
|-----------|--------------|
| Supabase | Free tier |
| OpenAI Embeddings | ~$5-10 |
| GPT-4o (descriptions) | ~$10-20 |
| RunPod (70B model) | ~$200-400 |
| **Total** | **~$220-430** |

---

## ğŸ“š Related Documents

### Crawler Documentation
- `docs/AI_AGENT_QUICKSTART.md` - **Start here** for new Claude agents
- `docs/AI_CRAWLER_APPROACH.md` - Full methodology and protocols
- `docs/GLOBAL_CONTEXT.md` - AccuLynx product overview
- `docs/EPIC_KB_GUIDED_CRAWLING.md` - Epic documentation

### Project History  
- `REFACTORING_PLAN.md` - Detailed migration plan with phases
- `DEPRECATED.md` - Deprecated components (preserved for future Action Agent)
- `PROGRESS.md` - Historical development log

---

## ğŸ“ License

Private - Internal Use Only
